{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set paths for the dataset\n",
    "train_data_path = 'C:/Users/Surya/Downloads/CODECRAFT_ML_04/archive (3)/leapGestRecog'\n",
    "validation_data_path = 'C:/Users/Surya/Downloads/CODECRAFT_ML_04/archive (3)/leapGestRecog'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Surya/Downloads/CODECRAFT_ML_04/archive (3)/leapGestRecog\n",
      "40000\n"
     ]
    }
   ],
   "source": [
    "# Find the Length of the Dataset (Number of Samples)\n",
    "train_data_len = sum([len(files) for r, d, files in os.walk(train_data_path)])\n",
    "validation_data_len = sum([len(files) for r, d, files in os.walk(validation_data_path)])\n",
    "print(train_data_path)\n",
    "print(validation_data_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset length: 40000\n",
      "Validation dataset length: 40000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training dataset length: {train_data_len}\")\n",
    "print(f\"Validation dataset length: {validation_data_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing (Image Augmentation for Training)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize images to [0, 1]\n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True\n",
    ")\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 images belonging to 11 classes.\n",
      "Found 40000 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prepare generators for loading data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,  # Path to training data\n",
    "    target_size=(64, 64),  # Resize images to 64x64 pixels\n",
    "    batch_size=32,  # Batch size\n",
    "    class_mode='categorical'  # Since it's a classification problem\n",
    ")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_path,  # Path to validation data\n",
    "    target_size=(64, 64),  # Resize images to 64x64 pixels\n",
    "    batch_size=32,  # Batch size\n",
    "    class_mode='categorical'  # Since it's a classification problem\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build A gesture recognition model may use a CNN to classify hand gestures based on image inputs.\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(train_generator.num_classes, activation='softmax')  # Output layer for classification\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 1562s 1s/step - loss: 2.3631 - accuracy: 0.1852\n",
      "Test Accuracy: 0.18520000576972961\n"
     ]
    }
   ],
   "source": [
    "# Save the Model\n",
    "model.save('gesture_model.h5')\n",
    "\n",
    "\n",
    "# Evaluate the Model on Validation Data\n",
    "test_loss, test_acc = model.evaluate(validation_generator)\n",
    "print(f\"Test Accuracy: {test_acc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
